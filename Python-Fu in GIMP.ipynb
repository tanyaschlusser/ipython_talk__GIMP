{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Happy GIMP-sgiving, ChiPy!\n",
    "\n",
    "Code available at [http://bit.ly/chipy_gimp][gimp_code].\n",
    "\n",
    "<img src='http://i.ytimg.com/vi/u6ggvSmlctU/maxresdefault.jpg' style='width:600px;' alt='pumpkin and chipmunk'></img>\n",
    "\n",
    "[gimp_code]: https://github.com/tanyaschlusser/ipython_talk__GIMP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## GIMP - GNU Image Manipulation Program\n",
    "\n",
    "GIMP is an [open source][gimp-repo] substitute for [Adobe Photoshop][lifehacker_gimp], and is what you should\n",
    "use to make a ChiPy T-shirt design!\n",
    "\n",
    "<table>\n",
    "<tr>\n",
    "<td><img src=\"https://static.skillshare.com/uploads/video/thumbnails/8a22be5a4fb1c2d2bafa7c5daa6e9a9f/original\" alt=\"GIMP logo\" style=\"width:150px;float:left;border:1px solid black;\"></img></td>\n",
    "<td style=\"font-size:200%\">≈</td>\n",
    "<td><img src=\"https://upload.wikimedia.org/wikipedia/commons/9/92/Adobe_Photoshop_CS6_icon.svg\" alt=\"Adobe paint logo\" style=\"width:150px;\"></img></td>\n",
    "</tr>\n",
    "</table>\n",
    "\n",
    "[gimp-repo]: http://developer.gimp.org/git.html\n",
    "[lifehacker_gimp]: http://lifehacker.com/how-to-make-the-gimp-work-more-like-photoshop-1551318983"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## GIMP introduction\n",
    "\n",
    "1. Get GIMP: follow [the installation][gimp-installation] according to your OS\n",
    "2. Open a file: `Gimp → File → Open → '<filename>.<ext>'`\n",
    "3. Use the GUI ... apparently it's like Adobe Photoshop ... (startup GIMP for demo now)\n",
    "\n",
    "[gimp-installation]: http://www.gimp.org/downloads/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# I'll repeat myself in the GUI and shell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### GIMP Concepts demo\n",
    "First you open an image to edit. The GUI tools include pencils and paintbrushes with various patterns and selection tools.\n",
    "\n",
    "#### Drawables\n",
    "* **Layers**: different images / copies of images overlaid with transparency\n",
    "* **Channels**: different sets of visible colors or selections -- like a saved mask\n",
    "* **Selections**: a collection of pixels that is currently active\n",
    "* **Tile Object**: a 64x64 region of pixels being edited -- tiling is done to save memory\n",
    "* **Pixel Region**: a user-defined rectangle of pixels in memory (can be bigger than a tile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### GIMP GUI demo\n",
    "\n",
    "A pair of colorblind Japanese scientists have a [great page on data presentation for colorblind people][co-jp]. Two of my past 5 supervisors, and 1 in 3 males, are colorblind.\n",
    "\n",
    "What they see is:\n",
    "\n",
    "\n",
    "<img src=\"http://jfly.iam.u-tokyo.ac.jp/color/image/slide_simulation.jpg\" alt=\"simulated colorblind image\"></img>\n",
    "\n",
    "\n",
    "What they ask readers to create is:\n",
    "\n",
    "<table>\n",
    "<tr>\n",
    "<td><img src=\"img/colorblind_fluorescent.jpg\" alt=\"fluorescent image with colors bad for colorblind people\" style=\"width:180px;float:left;\"></img></td>\n",
    "<td style=\"font-size:200%\">→</td>\n",
    "<td><img src=\"img/fixed_fluorescent.jpg\" alt=\"fluorescent image with colors ok for colorblind people\" style=\"width:180px;\"></img></td>\n",
    "</tr>\n",
    "</table>\n",
    "\n",
    "[co-jp]: http://jfly.iam.u-tokyo.ac.jp/color/#stain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Channels → change colors → save to file\n",
    "\n",
    "1. Open the file\n",
    "2. Windows → Dockable Dialogs → Channels\n",
    "3. Select the red one and copy it to the blue one\n",
    "\n",
    "    1. Highlight only the Red component\n",
    "    2. [Control] + [Click] → Channel to Selection\n",
    "    3. Edit → Copy\n",
    "    4. Highlight only the Blue component\n",
    "    5. Tools → Color Tools → Colorize ...  Choose the maximum Hue, Saturation, Lightness\n",
    "    \n",
    "4. File → Export As ... "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Aside (Wait ... what about Inkscape?)\n",
    "\n",
    "\n",
    "<table>\n",
    "<tr>\n",
    "<td><img src=\"http://colibre.org/wp-content/uploads/2015/01/inkscape-logo.png\" alt=\"Inkscape logo\" style=\"width:150px;float:left;\"></img></td>\n",
    "<td style=\"font-size:200%\">≈</td>\n",
    "<td><img src=\"https://upload.wikimedia.org/wikipedia/commons/a/a0/Adobe_Illustrator_icon_CS6.svg\" alt=\"Adobe Illustrator logo\" style=\"width:150px;\"></img></td>\n",
    "</tr>\n",
    "<tr style=\"height:1em\"></tr>\n",
    "</table>\n",
    "\n",
    "\n",
    "Inkscape is [open source][inkscape-repo] too, and a substitute for Adobe Illustrator. It's a vector graphics program that uses Scalable Vector Graphics (SVG) as its native format. GIMP is a bitmap program...you manipulate pixels not shapes / vector descriptions.\n",
    "\n",
    "<!--\n",
    "### Just to clear up and differentiate what's what\n",
    "* I love Inkscape but right now if I'm going to manipulate vector drawings programmatically it will be using Javascript and the incredible [D3.js library][d3js] (sorry, Python!).\n",
    "* But I'll use Inkscape to draw them.\n",
    "* As for GIMP ... I can't think of a better way to interact with pixels.\n",
    " * Maybe with OpenCV (cv2 for Python) ... -->\n",
    "\n",
    "\n",
    "[inkscape-repo]: https://inkscape.org/en/develop/inkscape-bzr/\n",
    "[d3js]: http://d3js.org/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### GIMP _should_ be called:\n",
    "# Greatest ever Image Manipulation Program\n",
    "\n",
    "... Because it's extensible via Python!!!\n",
    "\n",
    "\n",
    "I can't quite tell who is responsible for writing the library.\n",
    "James Henstridge, from Australia, for sure [wrote the documentation][gimp-python-docs]\n",
    "and a bunch of examples.\n",
    "\n",
    "\n",
    "## Scikit - Image\n",
    "\n",
    "A few weeks ago, there was talk on the listserv about [Scikit-Image][sk-img] and how it was used to make (I think) the composite of Pluto. I hadn't heard of it until then.\n",
    "\n",
    "If someone who knows Scikit-Image can comment about similarities, difference, and tradeoffs after I'm done that would be kind of cool.\n",
    "\n",
    "[sk-img]: http://scikit-image.org/\n",
    "[beginning-gimp]: http://gimpbook.com/index.html\n",
    "[gimp-python-docs]: http://www.gimp.org/docs/python/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## The GIMP Python API\n",
    "\n",
    "* GIMP ships with Python:\n",
    "    + Filters → Python-fu → Console\n",
    "    + on my mac the executable is at: `/Applications/GIMP.app/Contents/MacOS/python`\n",
    "    + with libraries at: `/Applications/GIMP.app/Contents/Resources/lib/python2.7`\n",
    "* [gimpfu][gimp-python] is a set of Python modules that wrap the C library `libgimp`\n",
    "* There are two major parts:\n",
    "    * `gimpfu.pdb`, the Procedural Database, wraps all of the registered functions\n",
    "    * `gimpfu.gimp` contains convenience objects for more powerful manipulation\n",
    "\n",
    "#### Links:\n",
    "[The Python-specific API][gimp-python] | [Example scripts][gimpbook] | [The Procedural Database][pdb-doc]\n",
    "\n",
    "[gimp-python]: http://www.jamesh.id.au/software/pygimp/\n",
    "[gimpbook]: http://gimpbook.com/scripting/\n",
    "[pdb-doc]: http://docs.gimp.org/en/plug-in-dbbrowser.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Gimpfu of the colorblind thing again\n",
    "\n",
    "```\n",
    "# See what was imported already\n",
    "#   (run during window startup:  from gimpfu import *)\n",
    "print '\\n'.join(obj for obj in dir())\n",
    "\n",
    "# Exclude the enums.\n",
    "print '\\n'.join(\n",
    "        obj for obj in dir()\n",
    "        if not obj.startswith('__') and\n",
    "        not obj == obj.upper())\n",
    "\n",
    "# What's the path?\n",
    "gimp.__file__\n",
    " \n",
    "import sys\n",
    "sys.executable\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### ... In the Python-Fu console:\n",
    "#### Load the image.\n",
    "\n",
    "```\n",
    "# Load the image\n",
    "path = '/Users/tanyaschlusser/Code/git/ipython/ipython_talk__GIMP/img'\n",
    "img = pdb.gimp_file_load(path + '/colorblind_fluorescent.jpg', '')\n",
    "\n",
    "gimp.Display(img)  # Create a new image window\n",
    "gimp.displays_flush()  # Show the new image window\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### ... In the Python-Fu console:\n",
    "#### Copy the red channel into the clipboard, paste it into the blue channel, and save\n",
    "\n",
    "```\n",
    "# Copy the red channel\n",
    "red = pdb.gimp_channel_new_from_component(img, RED_CHANNEL, 'red')\n",
    "img.add_channel(red)\n",
    "pdb.gimp_edit_copy(red)\n",
    "\n",
    "# Turn off everything but the blue channel\n",
    "pdb.gimp_image_set_component_active(img, RED_CHANNEL, False)\n",
    "pdb.gimp_image_set_component_active(img, GREEN_CHANNEL, False)\n",
    "pdb.gimp_image_set_component_active(img, BLUE_CHANNEL, True)\n",
    "\n",
    "# Paste the image into a layer (there is only one layer right now)\n",
    "lyr = pdb.gimp_edit_paste(img.layers[0], True)\n",
    "pdb.gimp_floating_sel_anchor(lyr)\n",
    "\n",
    "# Save\n",
    "new_filename = \"fixed2\".join(img.filename.split('colorblind'))\n",
    "pdb.gimp_file_save(img, img.layers[0], new_filename, new_filename)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Making the code a GIMP plugin\n",
    "\n",
    "The GIMP plugin documentation for Python is old.\n",
    "The [GIMP Python docs][gimp-python] was last updated in 2006.\n",
    "The most detailed resource I've found is\n",
    "[Frédéric Jaume's tutorial][jaume-py], made in 2011; he's also\n",
    "made recent comments about updating the site, but it is a little wrong\n",
    "sometimes.\n",
    "<!-- | ([James Henstridge examples][jamesh], 2005) | ([GIMP Book][gimpbook], 2009) | ([IBM GIMP for Python][ibm-gimp], 2011) | -->\n",
    "\n",
    "#### Or just copy what was shipped with your GIMP:\n",
    "For the most up-to-date definition of the plugin registration function, open the Python-Fu console, type `import gimpfu`, and then use `help(gimpfu)` or `help(gimpfu.register)`. \n",
    "\n",
    "##### To find where to put the files:\n",
    "GIMP → Preferences  (will open a window)\n",
    " → Folders → Plug-ins\n",
    " \n",
    "One folder is for system plug-ins, the other for user plug-ins:\n",
    "<img src=\"img/preferences.png\" alt=\"the Preferences window showing the folders where the plugins are stored\" style=\"width:500px;\"></img>\n",
    "\n",
    "\n",
    "[gimp-python]: http://www.gimp.org/docs/python/\n",
    "[jamesh]: http://www.jamesh.id.au/software/pygimp/\n",
    "[gimpbook]: http://gimpbook.com/scripting/\n",
    "[ibm-gimp]: http://www.ibm.com/developerworks/opensource/library/os-autogimp/index.html#resources\n",
    "[jaume-py]: http://www.exp-media.com/gimp-python-tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### ... The code itself is just Python\n",
    "\n",
    "The `from gimpfu import *` gives you all of the constants, the procedural database (`pdb`), and `gimp`... then everything else is just Python:\n",
    "\n",
    "```\n",
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "from gimpfu import *\n",
    "import os\n",
    "\n",
    "def red_to_magenta(img):\n",
    "    # Create a new image window\n",
    "    gimp.Display(img)\n",
    "    # Show the new image window\n",
    "    gimp.displays_flush()\n",
    "    gimp.context_push()\n",
    "    img.undo_group_start()\n",
    "    red = pdb.gimp_channel_new_from_component(\n",
    "            img, RED_CHANNEL, 'red')\n",
    "    img.add_channel(red)\n",
    "    pdb.gimp_edit_copy(red)\n",
    "\n",
    "    pdb.gimp_image_set_component_active(\n",
    "            img, RED_CHANNEL, False)\n",
    "    pdb.gimp_image_set_component_active(\n",
    "            img, GREEN_CHANNEL, False)\n",
    "    pdb.gimp_image_set_component_active(\n",
    "            img, BLUE_CHANNEL, True)\n",
    "\n",
    "    lyr = pdb.gimp_edit_paste(\n",
    "            img.layers[0], True)\n",
    "    pdb.gimp_floating_sel_anchor(lyr)\n",
    "    img.remove_channel(red)\n",
    "    img.undo_group_end()\n",
    "    gimp.context_pop()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### ... then register the script, and call `main()`\n",
    "There are 12 arguments to the `register` function. [Frédéric Jaume's blog][jaume-blog] describes them best. Here's an example:\n",
    "\n",
    "```\n",
    "register(\n",
    "    'python-fu-red-to-magenta',\n",
    "    'Red to magenta for colorblind people.',\n",
    "    'Add the red channel to the blue one.',\n",
    "    'Tanya Schlusser',     # author\n",
    "    'public domain',       # copyright\n",
    "    '2015',                # date\n",
    "    '_Red to magenta...',  # menu_path\n",
    "    'RGB*',                # image_types\n",
    "    [   \n",
    "     (PF_IMAGE, 'img', 'Input image', None)\n",
    "    ],   # Arg type, name, description, default\n",
    "    [],  # Return values\n",
    "    red_to_magenta,  # Function to call\n",
    "    menu=\"<Image>/Filters/Artistic/\"\n",
    "    )   \n",
    "\n",
    "\n",
    "main()\n",
    "```\n",
    "\n",
    "\n",
    "[jaume-blog]: http://www.exp-media.com/content/extending-gimp-python-python-fu-plugins-part-2\n",
    "[gimpbook-examples]: http://gimpbook.com/scripting/gimp-script-templates/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### ... and on the command line\n",
    "\n",
    "Modify the code to take an input file name and output file name. The important changes are:\n",
    "\n",
    "```\n",
    "register(\n",
    "    'python-fu-red-to-magenta-batch',\n",
    "    # Different function name, of course...\n",
    "    # [... skip the description, etc. ...]\n",
    "    #\n",
    "    '',  # The 'RGB*' becomes an empty string, meaning\n",
    "         # this function does not operate on an image.\n",
    "    [   \n",
    "     (PF_FILE, \"infile\", \"Path for input file\", \"\"),\n",
    "     (PF_DIRNAME, \"save-path\", \"Path for output filename\", \"\"),\n",
    "     (PF_STRING, \"filename\",  \"Filename for export\",  \"\")\n",
    "    ],\n",
    "    # [... skip the rest ... ]\n",
    "    )\n",
    "```\n",
    "\n",
    "\n",
    "The function call looks like:\n",
    "```python\n",
    "$ /Applications/GIMP.app/Contents/MacOS/GIMP  \\\n",
    ">  --no-interface  \\\n",
    ">  --batch='(python-fu-red-to-magenta-batch  \\\n",
    ">            RUN-NONINTERACTIVE  \\\n",
    ">            \"img/colorblind_fluorescent.jpg\"  \\\n",
    ">            \"out\"  \\\n",
    ">            \"fixed3.jpg\")'  \\\n",
    ">  --batch='(gimp-quit 0)'\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Python's `glob` standard library beat the glob libraries in GIMP\n",
    "So, just take an input directory and output directory...\n",
    "\n",
    "\n",
    "```\n",
    "register(\n",
    "    'python-fu-red-to-magenta-glob',\n",
    "    # \n",
    "    # [... skip everything else that's the same ...]\n",
    "    #\n",
    "    [   \n",
    "     (PF_STRING, \"in-path\", \"Path for input file\", \"\"),\n",
    "     (PF_DIRNAME, \"save-path\", \"Path for output filename\", \"\")\n",
    "    ],\n",
    "    # [... skip the rest ... ]\n",
    "    )\n",
    "```\n",
    "\n",
    "\n",
    "The function call looks like:\n",
    "\n",
    "\n",
    "```\n",
    "$ /Applications/GIMP.app/Contents/MacOS/GIMP  \\\n",
    ">  --no-interface  \\\n",
    ">  --batch='(python-fu-red-to-magenta-glob  \\\n",
    ">            RUN-NONINTERACTIVE  \\\n",
    ">            \"img/*.jpg\"  \\\n",
    ">            \"out\")'  \\\n",
    ">  -batch='(gimp-quit 0)'\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"https://quizzicalllama.files.wordpress.com/2013/08/lkbb8.jpg\" style=\"width:300px\"></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"http://opencv.org/wp-content/themes/opencv/images/logo.png\"\n",
    " alt=\"OpenCV logo\" style=\"float:right;\"></img>\n",
    "\n",
    "## Face detection\n",
    "\n",
    "\n",
    "[OpenCV][opencv] (Open Computer Vision) is a C / C++ project with computer vision tools.\n",
    "It has Python bindings. If you don't want to compile it yourself, use Anaconda:\n",
    "\n",
    "\n",
    "```\n",
    "$ cat << EOF > requirements.txt\n",
    "> opencv==2.4.8\n",
    "> ipython-notebook\n",
    "> EOF\n",
    "$\n",
    "$ conda create -n with_opencv python=2.7 --file=requirements.txt\n",
    "$ source activate with_opencv\n",
    "$ # source deactivate with_opencv  # (when you're done)\n",
    "```\n",
    "\n",
    "\n",
    "Or just download [the correct binaries][conda-repo], untar and unzip, and put everything where it is supposed to be yourself...\n",
    "\n",
    "[opencv]: http://opencv.org/\n",
    "[conda-repo]: https://repo.continuum.io/pkgs/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The code is on Github\n",
    "\n",
    "in this file:\n",
    "\n",
    "```\n",
    "opencv_facedetect.py \n",
    "```\n",
    "\n",
    "#### The output:\n",
    "\n",
    "\n",
    "<table><tr>\n",
    "<td>\n",
    "<img src=\"img/addams_family2_detected.png\" style=\"height:230px;padding:0\"></img>\n",
    "</td><td>\n",
    "<img src=\"img/addams_family_detected.png\" style=\"height:230px;padding:0\"></img>\n",
    "</td>\n",
    "</tr></table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "haarcascades = cv2.__file__.split('lib')[0] + 'share/OpenCV/haarcascades/'\n",
    "cascade_fn =  haarcascades + \"haarcascade_frontalface_alt.xml\"\n",
    "cascade = cv2.CascadeClassifier(cascade_fn)\n",
    "\n",
    "\n",
    "def detect(img, cascade, minSize=(20,20)):\n",
    "    rects = cascade.detectMultiScale(\n",
    "            img,\n",
    "            scaleFactor=1.05,\n",
    "            minNeighbors=4,\n",
    "            minSize=minSize,\n",
    "            flags = cv2.CASCADE_SCALE_IMAGE)\n",
    "    if len(rects) == 0:\n",
    "        return []\n",
    "    rects[:,2:] += rects[:,:2]\n",
    "    return rects\n",
    "\n",
    "\n",
    "def draw_rects(img, rects, color):\n",
    "    for x1, y1, x2, y2 in rects:\n",
    "        cv2.rectangle(img, (x1, y1), (x2, y2), color, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "img = cv2.imread('img/addams_family_2.jpg')\n",
    "\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "gray = cv2.equalizeHist(gray)\n",
    "\n",
    "rects = detect(gray, cascade)\n",
    "vis = img.copy()\n",
    "draw_rects(vis, rects, (0, 255, 0))\n",
    "cv2.imshow(\"facedetect\", vis)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# The model is a cascade made of Haar features\n",
    "\n",
    "Basically it's a tree.\n",
    "\n",
    "* Each node in the tree tests for a feature and position.\n",
    "* The model was trained on 160000+ features and selected 6000.\n",
    "* It quits as soon as a test fails, which is why this can be fast.\n",
    "* The algorithm was the first one ever used in demonstrating real-time face detection.\n",
    "* The code for real-time video detection, in Python, is included in the [OpenCV examples][haar-video]. The code I just showed was adapted from [this tutorial][haar-tutorial].\n",
    "\n",
    "<table><tr>\n",
    "<td><img src=\"http://docs.opencv.org/master/haar_features.jpg\" style=\"height:200px\"></td>\n",
    "<td><img src=\"http://docs.opencv.org/master/haar.png\" style=\"height:200px\"></td>\n",
    "</tr></table>\n",
    "\n",
    "[haar-video]: http://docs.opencv.org/modules/objdetect/doc/cascade_classification.html#cascadeclassifier-detectmultiscale\n",
    "[haar-tutorial]: http://docs.opencv.org/master/d7/d8b/tutorial_py_face_detection.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Connecting OpenCV + GIMP\n",
    "\n",
    "The Python in my GIMP is 2.7...so the libraries I just used for face detection should (hopefully) not break.\n",
    "\n",
    "#### Quick hack\n",
    "Append the extra locations in the Anaconda virtual environment to `sys.path` from GIMP's Python:\n",
    "\n",
    "```\n",
    "import sys\n",
    "\n",
    "sys.path.extend([\n",
    "    '//anaconda/envs/with_opencv/lib/python27.zip',\n",
    "    '//anaconda/envs/with_opencv/lib/python2.7',\n",
    "    '//anaconda/envs/with_opencv/lib/python2.7/plat-darwin',\n",
    "    '//anaconda/envs/with_opencv/lib/python2.7/plat-mac',\n",
    "    '//anaconda/envs/with_opencv/lib/python2.7/plat-mac/lib-scriptpackages',\n",
    "    '//anaconda/envs/with_opencv/lib/python2.7/lib-tk',\n",
    "    '//anaconda/envs/with_opencv/lib/python2.7/lib-old',\n",
    "    '//anaconda/envs/with_opencv/lib/python2.7/lib-dynload',\n",
    "    '//anaconda/envs/with_opencv/lib/python2.7/site-packages',\n",
    "    '//anaconda/envs/with_opencv/lib/python2.7/site-packages/setuptools-18.3.2-py2.7.egg'\n",
    "])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### So then I can identify faces...\n",
    "\n",
    "and for example put hats on them:\n",
    "\n",
    "<table><tr>\n",
    "<td><img src=\"img/addams_family_hat.jpg\" style=\"height:220px\"></td>\n",
    "<td><img src=\"img/BDFL_hat.jpg\" style=\"height:220px\"></td>\n",
    "</tr></table>\n",
    "\n",
    "\n",
    "Code is in `plug-ins/hat.py`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### And related to last month...\n",
    "\n",
    "Eigenvector decomposition (Principal Components Analysis) can be used in face (or object) recognition. A sample implementation exists in some [OpenCV face recognition sample code][opencv-facerec] which I converted to Python. It's in the file:\n",
    "\n",
    "```\n",
    "opencv_facerec.py\n",
    "```\n",
    "\n",
    "There are other algorithms too, besides the Principal Components (Eigenvector) method:\n",
    "\n",
    "[opencv-facerec]: http://docs.opencv.org/modules/contrib/doc/facerec/facerec_tutorial.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "createEigenFaceRecognizer\n",
      "createFisherFaceRecognizer\n",
      "createLBPHFaceRecognizer\n"
     ]
    }
   ],
   "source": [
    "print \"\\n\".join(f for f in dir(cv2) if 'face' in f.lower())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Data\n",
    "\n",
    "Data are from the AT&T research lab. The tutorial says this is the [easiest one to use][facerec-db]:\n",
    "\n",
    "```\n",
    "URL=http://www.cl.cam.ac.uk/research\n",
    "URL=${URL}/dtg/attarchive/pub/data/att_faces.tar.Z\n",
    "curl --compressed ${URL} | tar xzvf -\n",
    "```\n",
    "\n",
    "[facerec-db]: http://docs.opencv.org/modules/contrib/doc/facerec/facerec_tutorial.html#face-database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "###\n",
    "# Read the data\n",
    "#\n",
    "import glob\n",
    "import random\n",
    "\n",
    "att_dataset = glob.glob('orl_faces/s*/*.pgm')\n",
    "is_color = False\n",
    "pairs = []\n",
    "\n",
    "for fname in att_dataset:\n",
    "    img = cv2.imread(fname, is_color)\n",
    "    label = fname.split('/')[1].strip('s')\n",
    "    pairs.append([img, label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: 38\tactual: 38\tdistance:  982\n",
      "Predicted: 20\tactual: 20\tdistance:  891\n",
      "Predicted: 11\tactual: 11\tdistance:  499\n",
      "Predicted: 10\tactual: 10\tdistance: 1010\n",
      "Predicted:  3\tactual:  3\tdistance:  568\n",
      "Predicted:  1\tactual:  1\tdistance: 1368\n",
      "Predicted: 27\tactual: 27\tdistance:  356\n",
      "Predicted:  8\tactual:  8\tdistance:  739\n",
      "Predicted: 39\tactual: 39\tdistance:  583\n",
      "Predicted: 13\tactual: 13\tdistance:  180\n"
     ]
    }
   ],
   "source": [
    "principal_components = 8\n",
    "ntest = 10\n",
    "random.shuffle(pairs)\n",
    "train_img, train_label = zip(*pairs[:-ntest])\n",
    "train_label = np.array(train_label, dtype=np.int32)\n",
    "\n",
    "model = cv2.createEigenFaceRecognizer(principal_components)\n",
    "model.train(train_img, train_label)\n",
    "\n",
    "for img, label in pairs[-ntest:]:\n",
    "    # Need to make the image one big long row\n",
    "    flattened_img = img.reshape(img.size)\n",
    "    prediction, confidence = model.predict(flattened_img)\n",
    "    print \"Predicted: {:>2d}\\tactual: {:>2}\\tdistance: {:>4}\".format(\n",
    "            prediction, label, int(confidence))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Here's a look at the eigenvectors\n",
    "This code is in `opencv_show_eigenfaces.py`\n",
    "\n",
    "* Preallocate space...and set up to double the image size (for this talk)\n",
    "* Then show the plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def rescale(img):\n",
    "    ## the None is a pointer to the destination matrix (useful if in C).\n",
    "    return cv2.normalize(img, None, 0, 255, cv2.NORM_MINMAX, cv2.CV_8UC1)\n",
    "\n",
    "\n",
    "# Prepare a 3 x 5 array of images\n",
    "height, width = img.shape\n",
    "nrow, ncol = 3, 5\n",
    "scale = 2  # To make it big enough for projection onscreen\n",
    "imgarray = np.zeros((height * nrow, width * ncol), dtype=np.uint8)\n",
    "big_img = np.zeros((height * nrow * scale, width * ncol * scale), dtype=np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Show eigenvectors of the face recognition model.\n",
    "model = cv2.createEigenFaceRecognizer()  # empty ==> All the principal components\n",
    "model.train(train_img, train_label)\n",
    "W = model.getMat('eigenvectors')\n",
    "mean = model.getMat('mean')\n",
    "\n",
    "for i in range(nrow * ncol):\n",
    "    row = (i / ncol) * height\n",
    "    col = (i % ncol) * width\n",
    "    eigenvector = W[:,i]\n",
    "    # unflatten the vector\n",
    "    eigen_img = eigenvector.reshape(img.shape)\n",
    "    imgarray[row:(row+height), col:(col+width)] = rescale(eigen_img)\n",
    "\n",
    "big_img[:,:] = np.kron(imgarray, [[1,1],[1,1]])\n",
    "colorized_img = cv2.applyColorMap(big_img, cv2.COLORMAP_JET)\n",
    "cv2.imshow(\"eigenfaces\", colorized_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### The outcome: the first 15 principal components\n",
    "The colors are rescaled. Green is the middle and dark red / dark blue both mean intensity -- so people are most different along their hair and forehead, then ...\n",
    "\n",
    "<img src=\"img/eigenfaces.png\" alt=\"top 15 principal components\" style=\"width:600px\"></img>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Show the array of various projections of the same face.\n",
    "components = range(25, 400, 25)\n",
    "for i in range(nrow * ncol):\n",
    "    row = (i / ncol) * height\n",
    "    col = (i % ncol) * width\n",
    "    eigenvectors = W[ :,:components[i] ]\n",
    "    data = img.reshape((1, img.size))\n",
    "    projections = cv2.PCAProject(data, mean, eigenvectors.transpose())\n",
    "    proj_img = projections.dot(eigenvectors.transpose())\n",
    "    proj_img = proj_img.reshape(img.shape)\n",
    "    imgarray[row:(row+height), col:(col+width)] = rescale(proj_img)\n",
    "\n",
    "big_img[:,:] = np.kron(imgarray, [[1,1],[1,1]])\n",
    "cv2.imshow(\n",
    "        \"projections -- {} to {}\".format(components[0], components[-1]),\n",
    "        big_img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### The outcome: one face rendered with different numbers of principal components\n",
    "\n",
    "* The model we made was right almost all the time with only 8 principal components.\n",
    "* The images are evenly spaced in increments of 25 principal components.\n",
    "\n",
    "<img src=\"img/projectedfaces.png\" alt=\"same person with increasing number of principal components\" style=\"width:600px\"></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Last thing... Hour of Code!\n",
    "\n",
    "# December 13, 2015\n",
    "## 9 AM -- Northwestern University"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"400\"\n",
       "            height=\"300\"\n",
       "            src=\"https://www.youtube.com/embed/2DxWIxec6yo\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.YouTubeVideo at 0x102f9bed0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import YouTubeVideo\n",
    "YouTubeVideo(\"2DxWIxec6yo\")"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
